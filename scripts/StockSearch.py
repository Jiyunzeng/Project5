from fastapi import FastAPI, Query, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from pymongo import MongoClient
from kiwipiepy import Kiwi
from datetime import datetime
import re
import json
from openai import OpenAI
from typing import List, Optional
import Levenshtein
# jamo ë¼ì´ë¸ŒëŸ¬ë¦¬ëŠ” ë” ì´ìƒ í•„ìš”í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

# ---------------- API í‚¤ ì§ì ‘ ëª…ì‹œ ----------------
# âš ï¸ ì£¼ì˜: ì‹¤ì œ ìš´ì˜ í™˜ê²½ì—ì„œëŠ” ë°˜ë“œì‹œ í™˜ê²½ ë³€ìˆ˜ë¥¼ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤!
MONGO_URI = "mongodb+srv://kh:1234@cluster0.fbav0ho.mongodb.net/"
# â­ï¸ [ìˆ˜ì •] ì—¬ê¸°ì— ìœ íš¨í•œ API í‚¤ë¥¼ ë„£ì–´ì£¼ì„¸ìš”.

app = FastAPI()

# ---------------- CORS ì„¤ì • ----------------
origins = ["http://localhost:5173"]
app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ---------------- MongoDB ë° LLM í´ë¼ì´ì–¸íŠ¸ ì „ì—­ ë³€ìˆ˜ ì´ˆê¸°í™” ----------------
client: MongoClient = None
db = None
krx_col = None
naver_kospi_col = None
naver_kosdaq_col = None
client_llm: Optional[OpenAI] = None

@app.on_event("startup")
def startup_db_client():
    """ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘ ì‹œ DB ë° LLM ì—°ê²°/ê°ì²´ ì„¤ì •"""
    global client, db, krx_col, naver_kospi_col, naver_kosdaq_col, client_llm

    try:
        # 1. MongoDB ì—°ê²°
        client = MongoClient(MONGO_URI)
        client.admin.command('ping')
        db = client["stock"]
        krx_col = db["krx"]
        naver_kospi_col = db["naver_kospi"]
        naver_kosdaq_col = db["naver_kosdaq"]
        print("MongoDB ì—°ê²° ì„±ê³µ.")

        # 2. OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (LLM)
        if not OPENAI_API_KEY:
            raise ValueError("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        client_llm = OpenAI(api_key=OPENAI_API_KEY)
        print("OpenAI í´ë¼ì´ì–¸íŠ¸ ì¤€ë¹„ ì™„ë£Œ.")

    except Exception as e:
        print(f"ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        detail_msg = "ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨. DB ì—°ê²° ë˜ëŠ” API í‚¤ë¥¼ í™•ì¸í•˜ì„¸ìš”."
        if "API key" in str(e) or isinstance(e, ValueError):
            detail_msg = "OpenAI API í‚¤ ì„¤ì • ì˜¤ë¥˜. í‚¤ë¥¼ í™•ì¸í•˜ì„¸ìš”."
        raise HTTPException(status_code=503, detail=detail_msg)

@app.on_event("shutdown")
def shutdown_db_client():
    """ì• í”Œë¦¬ì¼€ì´ì…˜ ì¢…ë£Œ ì‹œ DB ì—°ê²° í•´ì œ"""
    global client
    if client:
        client.close()
        print("MongoDB ì—°ê²° í•´ì œ.")

# ---------------- í˜•íƒœì†Œ ë¶„ì„ê¸° ----------------
kiwi = Kiwi()

# ---------------- ëª¨ë¸ ì •ì˜ ----------------
class StockSearchResponse(BaseModel):
    code: str
    name: str
    market: str
    current_price: int | float | None = None
    change: str | None = None
    change_rate: str | None = None
    volume: int | None = None
    market_cap: int | None = None
    foreign_ratio: float | None = None
    per: float | None = None
    roe: float | None = None
    crawled_at: str | None = None
    chosung: str | None = None
    crawl_date: str | None = None

class SearchSuggestionResponse(BaseModel):
    results: list[StockSearchResponse]
    suggestion_original_query: str | None = None
    suggestion_converted_text: str | None = None
    suggestion_message: str | None = None
    suggestion_list: List[str] | None = None
    gpt_inferred_word: str | None = None

# ---------------- ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ì •ì˜ ----------------
CHOSUNG_LIST = ["ã„±","ã„²","ã„´","ã„·","ã„¸","ã„¹","ã…","ã…‚","ã…ƒ","ã……","ã…†","ã…‡","ã…ˆ","ã…‰","ã…Š","ã…‹","ã…Œ","ã…","ã…"]

def get_chosung(text: str) -> str:
    """í•œê¸€ ë¬¸ìë¥¼ ì´ˆì„±ìœ¼ë¡œ ë³€í™˜"""
    result = []
    for char in text:
        if "ê°€" <= char <= "í£":
            code = ord(char) - 0xAC00
            result.append(CHOSUNG_LIST[code // 588])
        else:
            result.append(char)
    return "".join(result)

def contains_only_chosung(text: str) -> bool:
    """í…ìŠ¤íŠ¸ê°€ ì „ë¶€ ì´ˆì„±ìœ¼ë¡œë§Œ ì´ë£¨ì–´ì ¸ ìˆëŠ”ì§€ í™•ì¸"""
    return bool(re.match(r'^[ã„±-ã…]+$', text))

def extract_korean_text(text: str) -> str:
    """í…ìŠ¤íŠ¸ì—ì„œ ì™„ì„±í˜• í•œê¸€ ë¬¸ìë§Œ ì¶”ì¶œ"""
    return "".join(char for char in text if "ê°€" <= char <= "í£")

def contains_chosung_mixed_with_korean(text: str) -> bool:
    """ì´ˆì„± ìëª¨ì™€ ì™„ì„±í˜• í•œê¸€ì´ ëª¨ë‘ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸"""
    has_chosung_jamo = bool(re.search(r'[ã„±-ã…]', text))
    has_korean_syllable = bool(re.search(r'[ê°€-í£]', text))
    return has_chosung_jamo and has_korean_syllable

def get_levenshtein_similarity(str1: str, str2: str) -> float:
    """ë‘ ë¬¸ìì—´ì˜ Levenshtein ê±°ë¦¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìœ ì‚¬ë„ (0.0~1.0)ë¥¼ ê³„ì‚°"""
    distance = Levenshtein.distance(str1, str2)
    max_len = max(len(str1), len(str2))
    if max_len == 0:
        return 0.0
    # ìœ ì‚¬ë„ = 1.0 - (ê±°ë¦¬ / ìµœëŒ€ ê¸¸ì´)
    return 1.0 - (distance / max_len)

# QWERTY ì˜ë¬¸ ìíŒì„ ë‘ë²Œì‹ í•œê¸€ ìëª¨ë¡œ ë§¤í•‘
KEY_MAP = {
    'q': 'ã…‚', 'w': 'ã…ˆ', 'e': 'ã„·', 'r': 'ã„±', 't': 'ã……', 'y': 'ã…›', 'u': 'ã…•', 'i': 'ã…‘', 'o': 'ã…', 'p': 'ã…”',
    'a': 'ã…', 's': 'ã„´', 'd': 'ã…‡', 'f': 'ã„¹', 'g': 'ã…', 'h': 'ã…—', 'j': 'ã…“', 'k': 'ã…', 'l': 'ã…£',
    'z': 'ã…‹', 'x': 'ã…Œ', 'c': 'ã…Š', 'v': 'ã…', 'b': 'ã… ', 'n': 'ã…œ', 'm': 'ã…¡',
    'Q': 'ã…ƒ', 'W': 'ã…‰', 'E': 'ã„¸', 'R': 'ã„²', 'T': 'ã…†', 'Y': 'ã…›', 'U': 'ã…•', 'I': 'ã…‘', 'O': 'ã…’', 'P': 'ã…–',
    'A': 'ã…', 'S': 'ã„´', 'D': 'ã…‡', 'F': 'ã„¹', 'G': 'ã…', 'H': 'ã…—', 'J': 'ã…“', 'K': 'ã…', 'L': 'ã…£',
    'Z': 'ã…‹', 'X': 'ã…Œ', 'C': 'ã…Š', 'V': 'ã…', 'B': 'ã… ', 'N': 'ã…œ', 'M': 'ã…¡',
}

def eng_to_kor_keyboard(text: str) -> str:
    """ì˜ë¬¸ ì…ë ¥ ë¬¸ìì—´ì„ í•œê¸€ í‚¤ë³´ë“œ ë°°ì—´ì— ë”°ë¼ ìëª¨ë¡œ ë³€í™˜"""
    return "".join(KEY_MAP.get(c, c) for c in text)

# ---------------- GPT ê¸°ë°˜ ì¢…ëª©ëª… ì œì•ˆ í•¨ìˆ˜ (ì¢…ëª© ëª©ë¡ ë°˜í™˜) ----------------
def get_gpt_suggestions(original_query: str, converted_query: str, best_match_names: List[str]) -> List[str]:
    """GPT-4o-minië¥¼ í˜¸ì¶œí•˜ì—¬ ê²€ìƒ‰ ì˜ë„ë¥¼ ë³´ì •í•˜ê³  ìœ ë ¥ ì¢…ëª©ëª… ë¦¬ìŠ¤íŠ¸ë¥¼ ì œì•ˆ ë°›ìŠµë‹ˆë‹¤."""
    global client_llm
    if client_llm is None:
        print("LLM í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. API í‚¤ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        return []

    match_list_str = ", ".join(best_match_names) if best_match_names else "ì œì‹œí•  ì°¸ê³  ì¢…ëª© ì—†ìŒ."

    prompt = f"""
ë‹¹ì‹ ì€ í•œêµ­ ì£¼ì‹ ì‹œì¥ ìƒì¥ ì¢…ëª©ëª… ê²€ìƒ‰ ì˜¤ë¥˜ë¥¼ ë³´ì •í•˜ëŠ” ì „ë¬¸ ë³´ì¡° AIì…ë‹ˆë‹¤.

ì‚¬ìš©ìì˜ ì…ë ¥ ì¿¼ë¦¬ëŠ” í‚¤ë³´ë“œ ì˜¤íƒ€ë¡œ ì¸í•´ ì˜ëª» ì…ë ¥ëœ ìƒíƒœì…ë‹ˆë‹¤. ì•„ë˜ ì£¼ì–´ì§„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ **ê°€ì¥ ê°€ëŠ¥ì„±ì´ ë†’ì€ 3~5ê°œì˜ í•œêµ­ ìƒì¥ ì¢…ëª©ëª…**ì„ ì˜ˆì¸¡í•˜ì„¸ìš”. íŠ¹íˆ **[1ì°¨ ìëª¨ ìœ ì‚¬ë„ ê¸°ë°˜ ì°¸ê³  ë¦¬ìŠ¤íŠ¸]** ë‚´ì—ì„œ ì •ë‹µì„ ì°¾ìœ¼ë ¤ëŠ” ë…¸ë ¥ì„ ê¸°ìš¸ì´ì„¸ìš”.

**--- ì§€ì¹¨ ë° ì œì•½ ì¡°ê±´ ---**
1. ì˜ˆì¸¡ ëŒ€ìƒ: ê°€ì¥ ê°€ëŠ¥ì„±ì´ ë†’ì€ **3~5ê°œì˜ ì¢…ëª©ëª…**ì„ ì˜ˆì¸¡í•´ì•¼ í•©ë‹ˆë‹¤.
2. ì¶œë ¥ í˜•ì‹: ì˜ˆì¸¡ëœ ì¢…ëª©ëª…ì„ ìš”ì†Œë¡œ ë‹´ëŠ” **JSON ë°°ì—´ í˜•ì‹**ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì•¼ í•©ë‹ˆë‹¤.
3. ì¶œë ¥ ì œì•½: JSON ë°°ì—´ ì™¸ì˜ ì–´ë– í•œ ì„¤ëª…ì´ë‚˜ ë¶€ê°€ í…ìŠ¤íŠ¸ë„ ì ˆëŒ€ í¬í•¨í•´ì„œëŠ” ì•ˆ ë©ë‹ˆë‹¤.
    
**--- ì…ë ¥ ì •ë³´ ---**
- ì…ë ¥ëœ ì¿¼ë¦¬ (ì˜ë¬¸): '{original_query}'
- ë³€í™˜ëœ ì¿¼ë¦¬ (í•œê¸€ ìëª¨): '{converted_query}'
- **[1ì°¨ ìëª¨ ìœ ì‚¬ë„ ê¸°ë°˜ ì°¸ê³  ë¦¬ìŠ¤íŠ¸]: {match_list_str}** **--- ì‹¤ì œ ìš”ì²­ì— ëŒ€í•œ ì˜ˆì¸¡ (JSON ë°°ì—´ë¡œë§Œ ì‘ë‹µ) ---**
"""
    try:
        response = client_llm.chat.completions.create(
            model="gpt-4o-mini-2024-07-18",
            messages=[
                {"role": "system", "content": "You are a specialized AI for correcting misspelled Korean stock names and must output ONLY a JSON array containing up to 5 suggested stock names."},
                {"role": "user", "content": prompt}
            ],
            response_format={"type": "json_object"},
            temperature=0.5,
            max_tokens=100
        )

        json_string = response.choices[0].message.content.strip()
        parsed_data = json.loads(json_string)

        if isinstance(parsed_data, list):
            return [name.strip() for name in parsed_data if isinstance(name, str) and name.strip()]

        if isinstance(parsed_data, dict):
            for key in parsed_data:
                if isinstance(parsed_data[key], list):
                    return [name.strip() for name in parsed_data[key] if isinstance(name, str) and name.strip()]

        return []

    except Exception as e:
        print(f"OpenAI API í˜¸ì¶œ ë˜ëŠ” JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
        return []


# ---------------- ğŸŒŸ [ìƒˆ í•¨ìˆ˜] GPT ê¸°ë°˜ ì¼ë°˜ ë‹¨ì–´ ì¶”ë¡  í•¨ìˆ˜ (ë‹¨ì–´ í•˜ë‚˜ ë°˜í™˜) ğŸŒŸ ----------------
def get_gpt_inferred_word(original_query: str, converted_query: str) -> str:
    """GPT-4o-minië¥¼ í˜¸ì¶œí•˜ì—¬ í‚¤ë³´ë“œ ì˜¤íƒ€ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê°€ì¥ ìœ ë ¥í•œ í•œêµ­ì–´ ì¼ë°˜ ë‹¨ì–´ë¥¼ í•˜ë‚˜ ì¶”ë¡ ë°›ìŠµë‹ˆë‹¤."""
    global client_llm
    if client_llm is None:
        return ""

    prompt = f"""
ë‹¹ì‹ ì€ í•œêµ­ì–´ í‚¤ë³´ë“œ ì˜¤íƒ€ë¥¼ ì „ë¬¸ì ìœ¼ë¡œ ë³µì›í•˜ëŠ” AIì…ë‹ˆë‹¤.

ì‚¬ìš©ìì˜ ì…ë ¥ ì¿¼ë¦¬ëŠ” í‚¤ë³´ë“œ ì˜¤íƒ€ë¡œ ì¸í•´ ì˜ëª» ì…ë ¥ëœ ìƒíƒœì…ë‹ˆë‹¤. ì•„ë˜ ì£¼ì–´ì§„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìê°€ ì˜ë„í–ˆì„ **ê°€ì¥ ê°€ëŠ¥ì„±ì´ ë†’ì€ í•œêµ­ì–´ ì¼ë°˜ ëª…ì‚¬(ë‹¨ì–´) í•˜ë‚˜**ë§Œ ì˜ˆì¸¡í•˜ì„¸ìš”.

**--- ì§€ì¹¨ ë° ì œì•½ ì¡°ê±´ ---**
1. ì˜ˆì¸¡ ëŒ€ìƒ: ê°€ì¥ ê°€ëŠ¥ì„±ì´ ë†’ì€ **í•œêµ­ì–´ ì¼ë°˜ ëª…ì‚¬ (ë‹¨ì–´) í•˜ë‚˜**ë§Œ ì˜ˆì¸¡í•´ì•¼ í•©ë‹ˆë‹¤.
2. ì¶œë ¥ í˜•ì‹: ì˜ˆì¸¡ëœ ë‹¨ì–´ **í•˜ë‚˜**ë§Œ ì‘ë‹µí•´ì•¼ í•©ë‹ˆë‹¤. JSON í˜•ì‹ì´ë‚˜ ë¶€ê°€ ì„¤ëª…ì€ ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
3. ì˜ˆì‹œ: ì…ë ¥ì´ 'tkatjd'ì´ë©´ ì¶œë ¥ì€ 'ì‚¼ì„±'ì´ì–´ì•¼ í•©ë‹ˆë‹¤. ì…ë ¥ì´ 'rnas'ì´ë©´ ì¶œë ¥ì€ 'ê°€ë‚˜'ì—¬ì•¼ í•©ë‹ˆë‹¤.
    
**--- ì…ë ¥ ì •ë³´ ---**
- ì…ë ¥ëœ ì¿¼ë¦¬ (ì˜ë¬¸ ì˜¤íƒ€): '{original_query}'
- ë³€í™˜ëœ ì¿¼ë¦¬ (í•œê¸€ ìëª¨): '{converted_query}'
"""
    try:
        response = client_llm.chat.completions.create(
            model="gpt-4o-mini-2024-07-18",
            messages=[
                {"role": "system", "content": "You are a specialized AI for correcting misspelled Korean words and must output ONLY the single most likely Korean noun."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.0, # ì •í™•í•œ ì¶”ë¡ ì„ ìœ„í•´ 0.0 ì„¤ì •
            max_tokens=20
        )
        inferred_word = response.choices[0].message.content.strip()

        # í•œêµ­ì–´ ì™„ì„±í˜• 2ê¸€ì ì´ìƒì¸ ê²½ìš°ì—ë§Œ ìœ íš¨í•˜ë‹¤ê³  íŒë‹¨
        if re.search(r'[ê°€-í£]{2,}', inferred_word):
            return inferred_word

        return ""

    except Exception as e:
        print(f"OpenAI API í˜¸ì¶œ ë˜ëŠ” ì¶”ë¡  ì‹¤íŒ¨: {e}")
        return ""

# ---------------- ê²€ìƒ‰ API (GPT ê¸°ë°˜ ì œì•ˆ í†µí•© ë²„ì „) ----------------
@app.get("/search", response_model=SearchSuggestionResponse)
def search_stocks(
        q: str = Query(..., min_length=1),
        use_chosung: bool = False
):
    global krx_col, naver_kospi_col, naver_kosdaq_col
    if krx_col is None:
        raise HTTPException(status_code=503, detail="ë°ì´í„°ë² ì´ìŠ¤ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    q = q.strip()
    if not q:
        return SearchSuggestionResponse(results=[])

    # 1. ì˜íƒ€ ìë™ ë³€í™˜ ë° í”Œë˜ê·¸ ì„¤ì •
    q_original = q
    q_converted_for_search = q
    is_eng_converted = False

    if re.match(r'^[a-zA-Z]+$', q):
        q_converted_for_search = eng_to_kor_keyboard(q)
        is_eng_converted = True

    q = q_converted_for_search

    is_pure_chosung = contains_only_chosung(q)
    is_hybrid_search = contains_chosung_mixed_with_korean(q) or is_eng_converted

    # 2. KRX ì»¬ë ‰ì…˜ì—ì„œ ì¢…ëª© ì½”ë“œ ê²€ìƒ‰ (ë©”ì¸ ê²€ìƒ‰ ë¡œì§)
    filter_query = {}

    if use_chosung or is_pure_chosung:
        filter_query = {"chosung": {"$regex": re.escape(q), "$options": "i"}}
    elif is_hybrid_search:
        chosung_pattern = get_chosung(q)
        and_filters = []
        and_filters.append({"chosung": {"$regex": re.escape(chosung_pattern), "$options": "i"}})
        if not is_eng_converted:
            korean_chars = list(extract_korean_text(q))
            if korean_chars:
                char_filters = [{"name": {"$regex": re.escape(char), "$options": "i"}} for char in korean_chars]
                and_filters.extend(char_filters)
        filter_query = {"$and": and_filters}
    else:
        # ì¼ë°˜ í‚¤ì›Œë“œ ê²€ìƒ‰ (ì¢…ëª©ëª… + ì¢…ëª©ì½”ë“œ ëª¨ë‘ ê²€ìƒ‰)
        tokens = kiwi.tokenize(q)
        keywords = [t.form for t in tokens if t.tag in ["NNG", "NNP", "SL", "SN", "SH"]]
        if not keywords:
            keywords = [q]

        or_conditions = []
        for kw in keywords:
            # ì¢…ëª©ëª… ê²€ìƒ‰
            or_conditions.append({"name": {"$regex": re.escape(kw), "$options": "i"}})
            # ì¢…ëª©ì½”ë“œ ê²€ìƒ‰ (ì •í™•íˆ ì¼ì¹˜í•˜ê±°ë‚˜ í¬í•¨)
            if re.match(r'^\d{1,6}$', kw):
                or_conditions.append({"code": {"$regex": f"^{kw.ljust(6, '0')}$", "$options": "i"}})  # ì •í™• ì¼ì¹˜ (ì• 0 ì±„ì›€)
                or_conditions.append({"code": {"$regex": re.escape(kw), "$options": "i"}})  # ë¶€ë¶„ ì¼ì¹˜

        filter_query = {"$or": or_conditions}

    krx_results = list(krx_col.find(filter_query, {"_id": 0}))
    target_codes = [doc['code'] for doc in krx_results if 'code' in doc]

    # 3. Naver ì‹œì„¸ ë°ì´í„° ë³‘í•©
    price_map = {}
    processed_results = []

    if naver_kospi_col is not None and naver_kosdaq_col is not None:
        price_filter = {"code": {"$in": target_codes}}
        kospi_prices = list(naver_kospi_col.find(price_filter, {"_id": 0}))
        kosdaq_prices = list(naver_kosdaq_col.find(price_filter, {"_id": 0}))
        price_map = {doc['code']: doc for doc in kospi_prices + kosdaq_prices}

        for krx_doc in krx_results:
            code = krx_doc.get('code')
            merged_doc = {**krx_doc}

            if code in price_map:
                naver_doc = price_map[code]
                merged_doc = {**naver_doc, **krx_doc}
                merged_doc['name'] = krx_doc.get('name', naver_doc.get('name'))
                merged_doc['chosung'] = krx_doc.get('chosung')
                merged_doc['market'] = krx_doc.get('market', naver_doc.get('market'))

            if isinstance(merged_doc.get("crawled_at"), datetime):
                merged_doc["crawled_at"] = merged_doc["crawled_at"].isoformat()
            if 'market' not in merged_doc or merged_doc['market'] is None:
                merged_doc['market'] = 'UNKNOWN'

            processed_results.append(merged_doc)
    else:
        processed_results = krx_results

    # ---------------- ğŸŒŸ 4. GPT ê¸°ë°˜ ìœ ì‚¬ ì¢…ëª© ì œì•ˆ ë¡œì§ (ë‹¨ì–´ ì¶”ë¡  ë¶„ë¦¬) ğŸŒŸ ----------------
    suggestion_list = None
    suggestion_message = None

    # ğŸ’¡ [í•µì‹¬ ìˆ˜ì •]: GPTì—ê²Œ ì¼ë°˜ ë‹¨ì–´ë§Œ ì¶”ë¡ í•˜ê²Œ ìš”ì²­
    gpt_inferred_word = None

    # ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ê³ , ìˆœìˆ˜ ì´ˆì„± ê²€ìƒ‰ì´ ì•„ë‹ˆë©°, ê¸¸ì´ê°€ 2ì ì´ìƒì¼ ë•Œ ì˜¤íƒ€ ë³´ì • ì‹œë„
    if (not processed_results) and (not is_pure_chosung) and (len(q_original) >= 2):

        suggested_names = []
        best_match_names = []
        q_search_jamo = get_chosung(q_converted_for_search)

        if q_search_jamo and krx_col is not None:
            # 1ì°¨ ìëª¨ ìœ ì‚¬ë„ ê³„ì‚° ë¡œì§
            all_krx_stocks = list(krx_col.find({}, {"_id": 0, "name": 1, "chosung": 1}))

            similarity_scores = []
            for stock in all_krx_stocks:
                stock_jamo = stock.get('chosung', '')
                if stock_jamo:
                    similarity = get_levenshtein_similarity(q_search_jamo, stock_jamo)
                    similarity_scores.append((similarity, stock['name']))

            similarity_scores.sort(key=lambda x: x[0], reverse=True)
            best_match_names = [name for score, name in similarity_scores if score > 0.3][:5]

        # 1. ì˜íƒ€ ì˜¤íƒ€ì¸ ê²½ìš°: GPTì—ê²Œ "ì‚¼ì„±"ê³¼ ê°™ì€ ì¼ë°˜ ë‹¨ì–´ í•˜ë‚˜ë¥¼ ì¶”ë¡ í•˜ê²Œ ìš”ì²­
        if is_eng_converted:
            print(f"DEBUG_INFERRED_WORD_CALL: Attempting to call GPT for word inference: original='{q_original}' and converted='{q_converted_for_search}'")
            gpt_inferred_word = get_gpt_inferred_word(q_original, q_converted_for_search)

            # 2. GPTì—ê²Œ ì¢…ëª©ëª… ëª©ë¡ì„ ìš”ì²­ (ê¸°ì¡´ í•¨ìˆ˜ ì‚¬ìš©)
            suggested_names = get_gpt_suggestions(q_original, q_converted_for_search, best_match_names)

        # í•œê¸€ ì˜¤íƒ€ì¸ ê²½ìš° (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
        elif not is_eng_converted:
            suggested_names = get_gpt_suggestions(q_original, q_original, best_match_names)

        if suggested_names:
            suggestion_list = suggested_names

            # ğŸŒŸ [ìµœì¢… ë©”ì‹œì§€]: GPTê°€ ì¶”ë¡ í•œ ì¼ë°˜ ë‹¨ì–´('ì‚¼ì„±')ë¥¼ ë¨¼ì € ì œì‹œ
            if is_eng_converted and gpt_inferred_word:
                suggestion_message = (
                    f"í˜¹ì‹œ **{gpt_inferred_word}**ì„(ë¥¼) ê²€ìƒ‰í•˜ì…¨ë‚˜ìš”? "
                    f"ê°€ì¥ ìœ ë ¥í•œ ì¢…ëª©ì€ **{suggested_names[0]}**ì…ë‹ˆë‹¤. "
                    f"[ì´ {len(suggestion_list)}ê°œ ìœ ì‚¬ ì¢…ëª© í™•ì¸]"
                )
                print(f"DEBUG_INFERRED_WORD_RESULT: Inferred word is '{gpt_inferred_word}'")
            else:
                # ì¼ë°˜ ë‹¨ì–´ ì¶”ë¡  ì‹¤íŒ¨ ë˜ëŠ” í•œê¸€ ì˜¤íƒ€ ì‹œ: ê¸°ì¡´ GPT ì¢…ëª©ëª… ì œì•ˆ ë°©ì‹ ìœ ì§€
                top_suggestion = suggested_names[0]
                suggestion_message = (
                    f"í˜¹ì‹œ **{top_suggestion}**ì„(ë¥¼) í¬í•¨í•œ ìœ ì‚¬ ì¢…ëª© (ì´ {len(suggestion_list)}ê°œ)ì„ ì°¾ìœ¼ì‹œë‚˜ìš”? [í´ë¦­í•˜ì—¬ í™•ì¸]"
                )

            print(f"DEBUG_GPT_SUGGESTION: GPT suggested {suggested_names}")

    # 5. ìµœì¢… ì‘ë‹µ ë°˜í™˜
    return SearchSuggestionResponse(
        results=processed_results,
        suggestion_original_query=q_original,
        suggestion_converted_text=q_converted_for_search if is_eng_converted else None,
        suggestion_message=suggestion_message,
        suggestion_list=suggestion_list,
        gpt_inferred_word = gpt_inferred_word
    )